from __future__ import annotations
from loguru import logger
from typing import List, Dict
from services.parsers import fetch_new_lots
from database import async_session_maker, LotRepository, UserRepository, UserPreferenceRepository
from services.notifications import send_email
from utils.formatters import format_rub, format_date
from config.settings import settings


def _matches_preferences(
	lot: Dict,
	customers: List[str] | None,
	nomenclature: List[str] | None,
	budget_min: int | None = None,
	budget_max: int | None = None
) -> bool:
	"""–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ª–æ—Ç–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
	cust_ok = True
	nom_ok = True
	budget_ok = True
	
	if customers:
		cust_ok = (lot.get("customer") in customers)
	
	if nomenclature:
		# –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã –∏–∑ config
		from config.nomenclature import check_nomenclature_match
		nom_ok = check_nomenclature_match(lot.get("title", ""), nomenclature)
	
	# –ü—Ä–æ–≤–µ—Ä–∫–∞ –±—é–¥–∂–µ—Ç–∞
	if budget_min is not None or budget_max is not None:
		budget = lot.get("budget", 0)
		if budget_min is not None and budget < budget_min:
			budget_ok = False
		if budget_max is not None and budget > budget_max:
			budget_ok = False
	
	return cust_ok and nom_ok and budget_ok


async def run_parsers_once() -> int:
	"""Fetch new lots and upsert them into the database, then notify interested users."""
	new_count = 0
	created: List[Dict] = []
	lots: List[Dict] = await fetch_new_lots()
	if not lots:
		logger.info("Parser returned no lots")
		return 0

	async with async_session_maker() as session:
		repo = LotRepository(session)
		for data in lots:
			lot_number = data.get("lot_number")
			if not lot_number:
				continue
			exists = await repo.get_by_lot_number(lot_number)
			if exists:
				continue
			
			# –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –ø–æ–ª—è –º–æ–¥–µ–ª–∏ Lot
			# –£–¥–∞–ª—è–µ–º –ø–æ–ª—è, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –º–æ–¥–µ–ª–∏: url, publish_date, parsed_at
			lot_data = {
				"platform_name": data.get("platform_name"),
				"lot_number": data.get("lot_number"),
				"title": data.get("title"),
				"description": data.get("description"),
				"budget": data.get("budget", 0.0),
				"deadline": data.get("deadline"),
				"status": data.get("status", "active"),
				"review_status": "not_viewed",  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω
			}
			# –î–æ–±–∞–≤–ª—è–µ–º –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–æ–ª—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ None
			if data.get("customer"):
				lot_data["customer"] = data.get("customer")
			if data.get("nomenclature"):
				lot_data["nomenclature"] = data.get("nomenclature")
			if data.get("url"):
				lot_data["url"] = data.get("url")
			if data.get("source"):
				lot_data["source"] = data.get("source")
			else:
				lot_data["source"] = "parser"  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
			
			# –°–æ–∑–¥–∞–µ–º –ª–æ—Ç –≤ –ë–î
			lot = await repo.create(**lot_data)
			created.append(data)
			new_count += 1
			
			# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∫–∞—á–∏–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é, –µ—Å–ª–∏ –µ—Å—Ç—å URL
			if data.get("url") and lot:
				try:
					from services.documentation import download_documentation_from_url, extract_text_from_file
					logger.info(f"Auto-downloading documentation for lot {lot.lot_number} from {data.get('url')}")
					
					# –°–∫–∞—á–∏–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é
					file_path = await download_documentation_from_url(data.get("url"), lot.lot_number)
					
					if file_path:
						# –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
						documentation_text = await extract_text_from_file(file_path)
						
						# –û–±–Ω–æ–≤–ª—è–µ–º –ª–æ—Ç –≤ –ë–î
						lot.documentation_path = file_path
						lot.documentation_text = documentation_text if documentation_text and not documentation_text.startswith("[–û—à–∏–±–∫–∞") else None
						lot.documentation_analyzed = False
						await repo.update(lot)
						
						logger.info(f"Documentation auto-downloaded for lot {lot.lot_number}: {file_path}")
					else:
						logger.warning(f"Could not auto-download documentation for lot {lot.lot_number}")
				except Exception as e:
					logger.error(f"Error auto-downloading documentation for lot {lot.lot_number}: {e}", exc_info=True)
					# –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏

	logger.info(f"Parser job: created {new_count} new lots")

	if new_count > 0:
		# Build personalized recipients map: email -> list of lots
		user_repo = UserRepository
		pref_repo = UserPreferenceRepository
		personal: dict[str, List[Dict]] = {}
		async with async_session_maker() as session:
			u_repo = user_repo(session)
			p_repo = pref_repo(session)
			active_users = await u_repo.get_all_active(limit=10000)
			for user in active_users:
				if user.role not in {"admin", "manager"}:
					continue
				if not user.contact_email:
					continue
				pref = await p_repo.get_or_create(user.id)
				if not pref.notify_enabled:
					continue
				# –§–∏–ª—å—Ç—Ä—É–µ–º —Å —É—á–µ—Ç–æ–º –±—é–¥–∂–µ—Ç–∞
				user_lots = [
					d for d in created
					if _matches_preferences(
						d,
						pref.customers,
						pref.nomenclature,
						pref.budget_min,
						pref.budget_max
					)
				]
				if user_lots:
					personal[user.contact_email] = user_lots
		# Fallback to global list if no matches for anyone
		if not personal and settings.NOTIFY_EMAILS:
			personal = {email: created for email in settings.NOTIFY_EMAILS}

		# Send per-user digests
		for email, lots_list in personal.items():
			subject = f"–ù–æ–≤—ã–µ –∑–∞–∫—É–ø–∫–∏ ({len(lots_list)})"
			rows = []
			for d in lots_list:
				rows.append(
					f"<li><b>{d['title']}</b> ‚Äî {format_rub(float(d['budget']))}, –¥–µ–¥–ª–∞–π–Ω {format_date(d['deadline'])}, –∑–∞–∫–∞–∑—á–∏–∫ {d.get('customer') or '-'}, ‚Ññ {d['lot_number']}</li>"
				)
			body = (
				"<p>–ü–æ–¥—Ö–æ–¥—è—â–∏–µ –Ω–æ–≤—ã–µ –ª–æ—Ç—ã:</p>"
				f"<ul>{''.join(rows)}</ul>"
				"<p>–≠—Ç–æ –∞–≤—Ç–æ–ø–∏—Å—å–º–æ –±–æ—Ç–∞ –ó–∞–∫—É–ø–∫–∏ –†–ú–ö–°–ò–ë.</p>"
			)
			await send_email(subject, body, [email])

	return new_count


async def run_parser_for_customer(customer_name: str) -> tuple[int, str]:
	"""
	–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–∞—Ä—Å–µ—Ä –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∑–∞–∫–∞–∑—á–∏–∫–∞
	
	Args:
		customer_name: –ù–∞–∑–≤–∞–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫–∞
	
	Returns:
		–ö–æ—Ä—Ç–µ–∂ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤—ã—Ö –ª–æ—Ç–æ–≤, —Å–æ–æ–±—â–µ–Ω–∏–µ –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ)
	"""
	from config.customers import get_customer_info, CUSTOMERS_CATALOG
	
	customer_info = get_customer_info(customer_name)
	
	if not customer_info:
		return 0, f"‚ùå –ó–∞–∫–∞–∑—á–∏–∫ '{customer_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–µ."
	
	parser_type = customer_info.get("parser_type")
	is_active = customer_info.get("is_active", False)
	
	if not parser_type or not is_active:
		return 0, "–¢—Ä–µ–±—É–µ—Ç—Å—è –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å –∫ B2B-Center API"
	
	# –ó–∞–ø—É—Å–∫–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –ø–∞—Ä—Å–µ—Ä
	if parser_type == "pavlik_static":
		from services.parsers.pavlik_parser import PavlikParser
		parser = PavlikParser()
		try:
			lots = await parser.parse_current_lots()
		except Exception as e:
			logger.error(f"Error parsing {customer_name}: {e}", exc_info=True)
			return 0, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {str(e)}"
	else:
		return 0, f"‚ùå –ü–∞—Ä—Å–µ—Ä —Ç–∏–ø–∞ '{parser_type}' –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω."
	
	if not lots:
		return 0, "üì≠ –ù–æ–≤—ã—Ö –ª–æ—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."
	
	# –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ—Ç—ã –≤ –ë–î
	new_count = 0
	created: List[Dict] = []
	
	async with async_session_maker() as session:
		repo = LotRepository(session)
		for data in lots:
			# –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∑–∞–∫–∞–∑—á–∏–∫ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
			if not data.get("customer"):
				data["customer"] = customer_name
			
			lot_number = data.get("lot_number")
			if not lot_number:
				continue
			
			exists = await repo.get_by_lot_number(lot_number)
			if exists:
				continue
			
			# –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –ø–æ–ª—è –º–æ–¥–µ–ª–∏ Lot
			# –£–¥–∞–ª—è–µ–º –ø–æ–ª—è, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –º–æ–¥–µ–ª–∏: url, publish_date, parsed_at
			lot_data = {
				"platform_name": data.get("platform_name"),
				"lot_number": data.get("lot_number"),
				"title": data.get("title"),
				"description": data.get("description"),
				"budget": data.get("budget", 0.0),
				"deadline": data.get("deadline"),
				"status": data.get("status", "active"),
				"review_status": "not_viewed",  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω
			}
			# –î–æ–±–∞–≤–ª—è–µ–º –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–æ–ª—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ None
			if data.get("customer"):
				lot_data["customer"] = data.get("customer")
			if data.get("nomenclature"):
				lot_data["nomenclature"] = data.get("nomenclature")
			if data.get("url"):
				lot_data["url"] = data.get("url")
			if data.get("source"):
				lot_data["source"] = data.get("source")
			else:
				lot_data["source"] = "parser"  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
			
			# –°–æ–∑–¥–∞–µ–º –ª–æ—Ç –≤ –ë–î
			lot = await repo.create(**lot_data)
			created.append(data)
			new_count += 1
			
			# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∫–∞—á–∏–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é, –µ—Å–ª–∏ –µ—Å—Ç—å URL
			if data.get("url") and lot:
				try:
					from services.documentation import download_documentation_from_url, extract_text_from_file
					logger.info(f"Auto-downloading documentation for lot {lot.lot_number} from {data.get('url')}")
					
					# –°–∫–∞—á–∏–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é
					file_path = await download_documentation_from_url(data.get("url"), lot.lot_number)
					
					if file_path:
						# –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
						documentation_text = await extract_text_from_file(file_path)
						
						# –û–±–Ω–æ–≤–ª—è–µ–º –ª–æ—Ç –≤ –ë–î
						lot.documentation_path = file_path
						lot.documentation_text = documentation_text if documentation_text and not documentation_text.startswith("[–û—à–∏–±–∫–∞") else None
						lot.documentation_analyzed = False
						await repo.update(lot)
						
						logger.info(f"Documentation auto-downloaded for lot {lot.lot_number}: {file_path}")
					else:
						logger.warning(f"Could not auto-download documentation for lot {lot.lot_number}")
				except Exception as e:
					logger.error(f"Error auto-downloading documentation for lot {lot.lot_number}: {e}", exc_info=True)
					# –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
	
	if new_count == 0:
		return 0, "üì≠ –ù–æ–≤—ã—Ö –ª–æ—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (–≤—Å–µ —É–∂–µ –µ—Å—Ç—å –≤ –±–∞–∑–µ)."
	
	logger.info(f"Parser for {customer_name}: created {new_count} new lots")
	
	# –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ
	message = f"‚úÖ <b>–ó–∞–ø—Ä–æ—Å –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ!</b>\n\n"
	message += f"üìä –ù–∞–π–¥–µ–Ω–æ –Ω–æ–≤—ã—Ö –ª–æ—Ç–æ–≤: {new_count}\n\n"
	
	# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –ª–æ—Ç–æ–≤
	for idx, lot in enumerate(created[:5], 1):
		message += f"{idx}. {lot.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')[:50]}...\n"
		message += f"   üí∞ {format_rub(float(lot.get('budget', 0)))}\n"
		message += f"   üÜî {lot.get('lot_number', 'N/A')}\n\n"
	
	if len(created) > 5:
		message += f"... –∏ –µ—â–µ {len(created) - 5} –ª–æ—Ç–æ–≤"
	
	return new_count, message


async def cleanup_expired_lots(days_before_expiry: int = 0) -> int:
	"""
	–û—á–∏—Å—Ç–∫–∞ –ª–æ—Ç–æ–≤ —Å –ø—Ä–æ—à–µ–¥—à–∏–º –¥–µ–¥–ª–∞–π–Ω–æ–º
	
	Args:
		days_before_expiry: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–æ –∏—Å—Ç–µ—á–µ–Ω–∏—è –¥–µ–¥–ª–∞–π–Ω–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0 - —Ç–æ–ª—å–∫–æ —É–∂–µ –ø—Ä–æ—à–µ–¥—à–∏–µ)
	                      –ï—Å–ª–∏ > 0, —Ç–æ —É–¥–∞–ª—è—é—Ç—Å—è –ª–æ—Ç—ã, —É –∫–æ—Ç–æ—Ä—ã—Ö –¥–µ–¥–ª–∞–π–Ω –∏—Å—Ç–µ–∫–∞–µ—Ç –≤ —Ç–µ—á–µ–Ω–∏–µ —ç—Ç–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–Ω–µ–π
	
	Returns:
		–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –ª–æ—Ç–æ–≤
	"""
	from database import async_session_maker, LotRepository
	
	try:
		async with async_session_maker() as session:
			repo = LotRepository(session)
			deleted_count = await repo.delete_expired_lots(days_before_expiry)
		
		if deleted_count > 0:
			if days_before_expiry == 0:
				logger.info(f"Cleanup: deleted {deleted_count} expired lots (deadline < now)")
			else:
				logger.info(f"Cleanup: deleted {deleted_count} expired lots (deadline < now - {days_before_expiry} day(s))")
		else:
			logger.info("Cleanup: no expired lots to delete")
		
		return deleted_count
	except Exception as e:
		logger.error(f"Error during cleanup of expired lots: {e}", exc_info=True)
		return 0
